<p align="center"><img src="https://zupimages.net/up/20/06/pd6r.png"></p>
<br/>

# SEMAINE 4
# Du 24 février 2020 au 28 février 2020
<br/>

## Lundi 24 février

* Schéma fait pour régir tous les cas possibles
* Rajout de certaines gestions de cas (pas tous réglés). Par exemple, pour certaines pages du PDF, la page ne commence pas avec une catégorie de produit et un pays juste après. Du coup, comme ces informations sont la continuité de la page précédente, parti pris de récupérer ces informations directement grâce à la dernière share récupérée dans la page précédente. 
Techniquement : on stocke la dernière share de la page précédente et on la donne en paramètre à la première share de la page d'après.

```bash
TODO :
- Inscription dans la BDD toujours à faire
```
<br/>

## Mardi 25 février

### Projet Scraping PDF
* Essai de récupération de la share précédente avant réinitialisation du tableau. :x: Sans succès
```bash
TODO :
- Inscription dans la BDD toujours à faire
```

### Réunion avec le Directeur de mon projet
* Occasion pour avoir mon ressenti sur la difficulté et ce que je mets en place pour les surmonter
* Point sur le nouveau projet sur lequel je vais occasionnellement intervenir pour le département R&D
* Compte Rendu d'Activité

### Projet Traduction R-Python
* Premier briefing théorique sur le projet et sur les objectifs poursuivis
* Élements reçus pour une prise de connaissance des scripts
<br/>

## Mercredi 26 février
> **Résultats :**
>* Récupération des pays dans la share précédente effectuée :muscle:
>* Récupération des catégories de produits dans la share précédente effectuée :muscle: 

:x: **MAIS** certaines catégories sont manquantes malgré tout...
* Problème trouvé : les données dont la taille dépasse la largeur d'une colonne ne sont pas traitées
* Méthode effectuée pour récupérer ces données. Mais pas encore validée
```bash
TODO :
- Inscription dans la BDD toujours à faire
```
<br/>

## Jeudi 27 février
> **Résultats :**
> * Inscription des nouvelles données dans la base de données
* Modifications pushées et merge request effectué
```bash
TODO :
- La méthode effectuée pour récupérer les produits n'est pas validée car peut menacer d'entrer en conflit avec d'autres PDFs - La modification proposée par mon référent consiste à déconstruire une approche émise avant mon arrivée - Trouver une nouvelle approche
- Transformation de mes données en objets à part entière - Passage de simples "String" en typages créés spécialement pour eux et imbrication de ces objets au sein des autres objets existants
```
<br/>

## Vendredi 28 février

### Projet Scraping PDF
* Préparation d'une notice interne parlant intégralement du projet :
    * Architecture
    * Fonctionnement (Docker, API,...)
    * Approche du projet (positionnement et parsing)

### Projet Traduction R-Python
* Installation de l'environnement de travail - Environnement Anaconda :
    * Python 3.7
    * R et RStudio
    * Packages : 
        * Matplotlib
        * Seaborn
        * Numpy
        * Pandas
        * PyReadr
        * TzLocal
        * Shiny
        * R.utils
        * Pracma
        * Rpy2 
* Depuis RStudio - Transformation du fichier RData en 3 dataframes R
* Depuis RStudio - Export des dataframes R en 3 CSV structurés
* Depuis Jupyter Notebooks - Début de la traduction :
    * Import des librairies
    * Lecture des CSV
    * Déclaration des variables


---------------------------------

**LA SEMAINE EN BREF :** 
- Faire des schémas / diagrammes préalablement à tout projet de développement pour gérer tous les cas possibles
- Transformation de données typées classiquement (String, int,...) en objets à part entière et avec un typage personnalisé (objet de type Country ou productCategory)
- Documentation technique globale du projet 
- Alternance entre du Java, R et Python - entraînement à s'adaptater aux différentes syntaxes
- Montée en compétence Java sur les objets et les imbrications d'objets
- Retour en zone de confort : R, Python, manipulation de dataframes

---------------------------------
